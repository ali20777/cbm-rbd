\documentclass[authoryear]{elsarticle}

% ------------ packages -------------

\usepackage[utf8]{inputenc}
\usepackage[OT1]{fontenc}
\usepackage{graphicx}
\usepackage[english]{babel}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{bm}

\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{booktabs}
\usepackage{tikz}

\usepackage{url}
\usepackage[bookmarks]{hyperref}

%\usetikzlibrary{shapes.misc,fit}
\usetikzlibrary{%
   arrows,%
   calc,%
   fit,%
   patterns,%
   plotmarks,%
   shapes.geometric,%
   shapes.misc,%
   shapes.symbols,%
   shapes.arrows,%
   shapes.callouts,%
   shapes.multipart,%
   shapes.gates.logic.US,%
   shapes.gates.logic.IEC,%
   er,%
   automata,%
   backgrounds,%
   chains,%
   topaths,%
   trees,%
   petri,%
   mindmap,%
   matrix,%
   calendar,%
   folding,%
   fadings,%
   through,%
   patterns,%
   positioning,%
   scopes,%
   decorations.fractals,%
   decorations.shapes,%
   decorations.text,%
   decorations.pathmorphing,%
   decorations.pathreplacing,%
   decorations.footprints,%
   decorations.markings,%
   shadows}

%\usepackage{hyperref}
%\usepackage[bookmarks]{hyperref}
%\usepackage[colorlinks=true,citecolor=red,linkcolor=black]{hyperref}

% ------------ custom defs -------------

\newcommand{\reals}{\mathbb{R}}
\newcommand{\posreals}{\reals_{>0}}
\newcommand{\posrealszero}{\reals_{\ge 0}}
\newcommand{\naturals}{\mathbb{N}}

\newcommand{\dd}{\,\mathrm{d}}

\newcommand{\mbf}[1]{\mathbf{#1}}
\newcommand{\bs}[1]{\boldsymbol{#1}}
\renewcommand{\vec}[1]{{\bm#1}}

\newcommand{\uz}{^{(0)}} % upper zero
\newcommand{\un}{^{(n)}} % upper n
\newcommand{\ui}{^{(i)}} % upper i

\newcommand{\ul}[1]{\underline{#1}}
\newcommand{\ol}[1]{\overline{#1}}

\newcommand{\Tsys}{T_\text{sys}}

\newcommand{\Rsys}{R_\text{sys}}
\newcommand{\lRsys}{\ul{R}_\text{sys}}
\newcommand{\uRsys}{\ol{R}_\text{sys}}

\newcommand{\fsys}{f_\text{sys}}
\newcommand{\Fsys}{F_\text{sys}}
\newcommand{\lFsys}{\ul{F}_\text{sys}}
\newcommand{\uFsys}{\ol{F}_\text{sys}}

\newcommand{\lgt}{\ul{g}}
\newcommand{\ugt}{\ol{g}}

\newcommand{\E}{\operatorname{E}}
\newcommand{\V}{\operatorname{Var}}
\newcommand{\wei}{\operatorname{Wei}} % Weibull Distribution
\newcommand{\ig}{\operatorname{IG}}   % Inverse Gamma Distribution

\newcommand{\El}{\ul{\operatorname{E}}}
\newcommand{\Eu}{\ol{\operatorname{E}}}

\def\yz{y\uz}
\def\yn{y\un}
%\def\yi{y\ui}
\newcommand{\yfun}[1]{y^{({#1})}}
\newcommand{\yfunl}[1]{\ul{y}^{({#1})}}
\newcommand{\yfunu}[1]{\ol{y}^{({#1})}}

\def\ykz{y\uz_k}
\def\ykn{y\un_k}

\def\yzl{\ul{y}\uz}
\def\yzu{\ol{y}\uz}
\def\ynl{\ul{y}\un}
\def\ynu{\ol{y}\un}
\def\yil{\ul{y}\ui}
\def\yiu{\ol{y}\ui}

\def\ykzl{\ul{y}\uz_k}
\def\ykzu{\ol{y}\uz_k}
\def\yknl{\ul{y}\un_k}
\def\yknu{\ol{y}\un_k}

\newcommand{\ykzfun}[1]{y\uz_{#1}}
\newcommand{\ykzlfun}[1]{\ul{y}\uz_{#1}}
\newcommand{\ykzufun}[1]{\ol{y}\uz_{#1}}

\def\nz{n\uz}
\def\nn{n\un}
%\def\ni{n\ui}
\newcommand{\nfun}[1]{n^{({#1})}}
\newcommand{\nfunl}[1]{\ul{n}^{({#1})}}
\newcommand{\nfunu}[1]{\ol{n}^{({#1})}}

\def\nkz{n\uz_k}
\def\nkn{n\un_k}
\newcommand{\nkzfun}[1]{n\uz_{#1}}
\newcommand{\nkzlfun}[1]{\ul{n}\uz_{#1}}
\newcommand{\nkzufun}[1]{\ol{n}\uz_{#1}}

\def\nzl{\ul{n}\uz}
\def\nzu{\ol{n}\uz}
\def\nnl{\ul{n}\un}
\def\nnu{\ol{n}\un}
\def\nil{\ul{n}\ui}
\def\niu{\ol{n}\ui}

\def\nkzl{\ul{n}\uz_k}
\def\nkzu{\ol{n}\uz_k}
\def\nknl{\ul{n}\un_k}
\def\nknu{\ol{n}\un_k}


\def\taut{\tau(\vec{t})}
\def\ttau{\tilde{\tau}}
\def\ttaut{\ttau(\vec{t})}
\def\tautk{\tau(\vec{t}_k)}

\def\MZ{\mathcal{M}\uz}
\def\MN{\mathcal{M}\un}

\def\MkZ{\mathcal{M}\uz_k}
\def\MkN{\mathcal{M}\un_k}

\def\PkZ{\Pi\uz_k}
\def\PkN{\Pi\un_k}
\newcommand{\PZi}[1]{\Pi\uz_{#1}}

\def\tnow{t_\text{now}}
\def\tpnow{t^+_\text{now}}


% ------------ options -------------

\allowdisplaybreaks

\journal{RESS}

\begin{document}

% ------------ frontmatter -------------

\begin{frontmatter}
\title{Condition-Based Maintenance for Complex Systems\\ based on Current Component Status\\ and Bayesian Updating of Component Reliability}

\author[tue]{Gero Walter}
\ead{g.m.walter@tue.nl}
\author[tue]{Simme Douwe Flapper}
\ead{s.d.p.flapper@tue.nl}

\address[tue]{School of Industrial Engineering, Eindhoven University of Technology, Eindhoven, Netherlands}


\begin{abstract}
We propose a new way of developing a condition-based maintenance policy for complex systems,
based not on a one-dimensional continuous degradation signal,
but on the status of all components within a system.

By means of the survival signature,
a generalization of the system signature allowing for multiple component types,
we obtain a predictive distribution for system survival time
(also known as RUL, remaining useful life)
based on which of the system's components currently function or not,
and the current age of the functioning components.

Component time to failure is modeled by a Weibull distribution with fixed shape parameter.
The scale parameter is iteratively updated in a Bayesian fashion
using the current (censored and non-censored) component lifetimes.
Each component type has a separate model that may also include test data.

The cost-optimal moment of repair for the system is obtained by minimizing the one-cycle unit cost rate.
The unit cost rate is recalculated at fixed time points,
leading to a dynamic policy since the aging of components and possible failures will change the cost-optimal moment of repair.
\end{abstract}

\begin{keyword}
condition-based maintenance \sep system reliability \sep remaining useful life \sep survival signature \sep one-cycle unit cost rate\end{keyword}
\end{frontmatter}


% ------------ manuscript -------------

\section{Introduction}
\label{intro}


***main message:
can do CBM for systems without degradation signal,
especially useful for redundant systems,
dynamic policy using one-cycle unit cost rate (exact, unlike renewal theorem based!),
using iterative Bayesian update of component models,
thus taking all information into account (history and current status)

***Bayesian approach allows component models to include expert info, test data (if available),
and information that can be gained from the behaviour of components in the running system
in the form of censored and non-censored component lifetimes 

***we argue that our approach is CBM because it takes current system state into account
and adjusts the moment of maintenance accordingly.

\subsection*{---------------------}
***general discussion on CBM as usual

***Condition-based maintenance (CBM) has received considerable attention in the literature.
The central idea is to maintain technical systems or components at just the right time,
that is, before they fail,
but not too early, in order to keep reliability high and operating costs low.
%most fully use the component's or system's lifetime and to save on maintenance work

***trade-off between risk of failure during operation
(can lead to costly downtime: idle workforce, missed production, penalties, loss of reputation)
and costs of premature maintenance
(wasting potential component / system lifetime, downtime cost, cost of maintenance work)

***so CBM must be based on some information about the state or health of the component / system.
Two ways: continuous monitoring CBM and inspection-based CBM.

***Continuous monitoring CBM policies are usually derived
using a directly observable continuously measurable condition / degradation signal,
or constructs such a signal or health status using indirect measurements.
Estimated time till failure (RUL) \citep{2014:rul-review, 2011:rul-review-statistical}
via distance of current signal level to a fixed known failure threshold.

***Inspection-based CBM via delay time model, modeling the time between detectable degradation and failure,
again time till failure via distance of current degradation level to fixed known failure threshold.

***In both cases, maintenance decision via control limit / threshold for the signal
(RUL not explicitely calculated)
by minimizing the expected unit cost rate,
which is often approximated using the renewal reward theorem.
%but in practice threshold often not known

\subsection*{---------------------}

Here we propose a different approach to CBM
for the case when no degradation signal for the system is available,
but system components can be identified and their functioning status
(working or not working) can be monitored.
In this situation, one can use the system's layout in reliability terms
(i.e., its reliability block diagram) and information on components' status
to directly calculate the RUL distribution,
and base the maintenance policy on this distribution.
(In fact, our approach can be seen as CBM based on a multivariate degradation signal,
where each component sends a binary signal, and the reliability block diagram is used
for sensor fusion.)

Our approach can also be seen as a generalization of policies for $k$ out of $N$ systems to arbitrary system layouts.
Furthermore, our approach allows for multiple types of components in the system,
with each component type having its own failure behaviour.

%We use a parametric model not for a degradation signal of the system or for the delay time, but for component lifetimes:
For each component type, we use the well-known Weibull distribution to model component lifetimes.
To keep the model simple and to demonstrate its feasability, we assume the shape parameter for each component type to be known,
focusing on learning of the scale parameter,
and that components fail independently.
These simplifying assumptions will often not hold in practice,
then the model can serve as a first approximation.
Generally, we see our contribution as opening up an entirely new way to derive CBM policies,
and thus consider the model in this paper more as a proof of concept,
where extension to more realistic models must happen in a second step.
As an example, it is possible to extend the model to learn also the shape parameter along the lines of
\cite{1969:soland},
but this is not included here as it would complicate presentation.
%need only to observe when a component fails,
%and expert information about expected component failure times.

The Bayesian approach to the Weibull model \citep[see, e.g.,][]{1996:mazzuchi-soyer} allows to integrate, for each component type,
three sources of information: expert knowledge, data from component tests,
and the status of components in the monitored system. %, i.e., current system condition.
These information sources are integrated into a single component model
using the iterative nature of Bayesian updating,
leading to a so-called posterior predictive distribution for the number of components surviving at any time in the future.

These predictive distributions are then used to calculate the exact distribution of system RUL
using the survival signature \citep{2012:survsign}.
(***we therefore accomplish the same as \cite{2013:si-et-al} for their situation.)

By its Bayesian nature, the system RUL distribution adequately reflects the uncertainties in RUL estimation
related to modeling and prediction \citep{2015:sankararaman},
readily adapting to any changes in component behaviour.
The use of conjugate priors means that we get explicit formulas for the RUL distribution,
so no numerical integration or simulation techniques are necessary.
This allows for a very frequent, or even real-time, update of the RUL distribution,
taking into account the changed structure when components have failed
and the information gain from updating the component reliability distributions.

Based on the RUL distribution at any current time $\tnow$,
the optimal moment of maintenance given all information available at $\tnow$
is then determined by minimizing the expected one-cycle unit cost rate.
The expected one-cycle unit cost rate, also known as one-cycle criterion
\citep{1984:ansell-bendell-humble,1996:mazzuchi-soyer,2006:coolen-schrijner-coolen},
makes the trade-off between preventive and corrective maintenance according to the current cycle only,
unlike the usually employed renewal based criterion,
which approximates the unit cost rate using a renewal argument \citep[p.~296]{1996:mazzuchi-soyer},
but is not suited for situations where one may whish to change the strategy per cycle \citep{2006:coolen-schrijner-coolen}.

Since the RUL distribution changes with current time $\tnow$,
the corresponding optimal moment of maintenance $\tau^*$ changes as well,
leading to a dynamic adaptive maintenance policy,
similar to a CBM policy based on a continuosly monitored degradation signal.
However, unlike such threshold-based CBM policies,
our approach allows to easily take into account the time needed to set up maintenance work (known as set-up time),
since it gives the optimal moment of maintenance as a time beyond current time $\tnow$,
and maintenance can be initiated as soon as $\tau^*$ approaches the set-up time.

In this paper, we assume that at the moment of maintenance,
all components in the system are replaced,
so the cost parameters in the unit cost rate must be determined accordingly.
One could instead consider other replacement schemes (e.g., replacing only the failed components),
or indeed optimize the unit cost rate over all possible replacement schemes,
since our method for RUL calculation can handle differently aged components. 
However, optimizing over replacement schemes opens up a full research programme on its own,
and for situations with high set-up costs,
as is typical for CBM applications,
the replace-all scheme is most likely the cost-optimal strategy. 


***figure of process: component priors $\to$ component posteriors $\to$ system RUL $\to$ $g(\tau)$ $\to$ $\tau^*$

***operation: recalculate $\tau^*$ at fixed dense grid of time points (quasi-continuous),
this makes sense even if nothing happens because the fact that components in the system still function
gives information on component distributions;
alternatively, do the recalculation every time when a component fails (failures contain the most information)

***model allows also to switch to corrective policy when $g(\tau)$ monotonely decreasing (then $\tau \to \infty$)

***Expert input in our model is, for each component type,
Weibull shape parameter, expected failure time (translated to scale parameter),
and expert info weight (how sure about mean failure time guess).
Component test data (can include right-censored observations) is optional.
Further input is system layout (reliability block diagram indicating which component belongs to which type)
and the cost parameters $c_p$ and $c_u$.

***here all expressed in time, but could also be in usage (number of cycles, etc).

***compare to $M^*$ out of $N$ policy:
we are dynamic (would mean for a $M^*$ out of $N$ policy that $M^*$ decreases over time due to component aging),
we learn about component lifetimes,
and we allow for set-up time



\section{Literature***}

***CBM via RUL, $M^*$ out of $N$ policies?

***also generally Bayesian methods in maintenance optimization?

***cite CBM review Olde Keizer, Flapper, Teunter, and other refs from it?


Example for Bayesian method in CBM via inspections: \cite{2007:wang-jia}
propose a model that uses Bayesian updating,
but the model aims to identify an optimal inspection interval.
%This is CBM via inspections, not CBM via continuous monitoring as we aim to do.

\begin{scriptsize}
Wang \& Jia (2007) have a model for defects arrival (homogeneous Poisson process with rate $\lambda$, so no aging),
model for delay time (time between defect and failure) is Weibull $h \sim \wei(\alpha,\beta)$,
and each of $\lambda, \alpha, \beta$ has a Gamma prior distribution.
The expected overall cost rate is then used to find a cost-optimal inspection interval.
For this they assume that failures are immediately repaired,
and defects found in an inspection are repaired during inspection.

They use prior predictive distributions for certain statistics (number of defects, number of failures, \ldots between $0$ and $T$)
to obtain prior values for the Gamma hyperparameters,
by solving prior predictive equations -- but give no detail on how they actually do this.

In the end they actually do not advocate to calculate the posterior expected cost rate (15),
but rather plug in posterior estimates for $\lambda, \alpha, \beta$,
so neglecting uncertainty in estimation.
(We do not assume a parametric distribution for delay time,
it rather arises as a consequence of the system layout and component failure distributions.)

\end{scriptsize}

Example for Bayesian method in CBM with continuous monitoring: \cite{2011:elwany-et-al}
(exponential degradation model, whose parameters $\theta'$ and $\beta$ each have a prior
which is updated using the degradation signal history,
and use total expected infinite-horizon discounted cost to determine the maintenance policy,
RUL not explicitely calculated)

Example for Bayesian method in prediction of system remaining useful life: \cite{2012:sun-et-al}
(constructs health index for a system based on sensor measurements,
health status prediction is updated sequentially,
leads to RUL distribution like our method,
but no link from RUL to maintenance decision)

\cite{2013:si-et-al} do CBM with continuous monitoring for a single component,
taking into account the whole degradation path history.
The authors provide exact expressions for the RUL distribution, which is updated in an empirical Bayesian framework using conjugate priors.
The RUL distribution is used to construct a replacement decision model using the unit cost rate via renewal reward
(eq. 35)\\
***this is most similar to what we do: exact RUL distribution $\to$ maintenance decision,
but we have component status instead of degradation signal as basis for RUL,
and we model epistemic uncertainties!\\

\cite{2011:kim-et-al} develop a periodic monitoring CBM policy
where a maintenance decision is triggered when
a Bayesian control chart (a sequentially updated health indicator) %posterior probability that system is in a 'warning' state
exceeds a control limit (threshold) that is determined
by minimizing the expected average cost per time unit.
(We use the same cost criterion, but base the maintenance decision directly on our exact RUL estimation.)

***typical recent example for Bayesian network models in maintenance -- could also cover system reliabilty terrain***
maybe Jones et al (RESS 95:3, 2010) ``The use of Bayesian network modelling for maintenance planning in a manufacturing industry'',
or Bouaziz et al (2013) ``Towards Bayesian network methodology for predicting equipment health factor of complex semiconductor systems''

\begin{scriptsize}
Bayesian networks (BNs) are a very general method to jointly model multiple dependent random variables in a Bayesian way. 
This needs assessments of conditional independece relations, and conditional probability models for each variable,
the latter often in form of conditional probability tables (discrete variables).
A Bayesian network models probabilistic relations between variables,
unlike a reliability block diagram, which gives a deterministic relation
between the status of components and the system state.

One could model a system as a BN (each component is a variable),
but that would add a lot of complications.
Most algorithms for BNs assume discrete distributions,
and do not scale well to large networks (many tasks are NP-hard).

The above papers seem to use a BN to model a degradation signal or (system) health index (have to check again to be sure).
Our approach is different, as we get an exact formulation for the system RUL directly.

\end{scriptsize}


\section{***summary of ASCE-ASME paper method minus sets of priors}


We consider a system with components of $k=1,\ldots,K$ different types;
for each type $k$, there are $n_k$ exchangeable components in the system.

***example reliability block diagram

component model: weibull with fixed shape,
inverse gamma prior on scale parameter,
fix priors via expected lifetime and prior strength,

test data inclusion
(write down explicit formula for test data including censored observations),
noninformatiove censoring

RUL via survival signature,
posterior predictive distributions,
system reliability curve (RUL) as output,

output is the current system reliability curve
taking into account the current system state,
including the current ages of system components, 
and the lifetime histories of all component types,
including test data and expert assessments.

***RUL model description below follows closely \cite{2016:walter-coolen},
which describes the same RUL model.
However, \cite{2016:walter-coolen} does not consider maintenance policies,
and focuses on a generalization of the RUL model using sets of priors for the component models
(effectively parametric P-boxes),
allowing for vague and partial prior specifications,
and sensitivity to prior-data conflict.


\subsection{Bayesian update of Weibull component models}
\label{sec:weibull}

Here we describe the model for the component lifetimes,
together with the Bayesian update procedure which allows to include
expert knowledge, component tests, and information from the currently monitored components in the system.

For each type $k$ component, we assume that the lifetime $T_{k,i}$ ($i=1,\ldots,n_k$, $k = 1, \ldots, K$)
is Weibull distributed with fixed shape parameter $\beta_k > 0$,
in short $T_{k,i} \mid \lambda_k \sim \wei(\beta_k,\lambda_k)$,
with density and cdf
\begin{align}
\label{eq:weibulldens}
f(t_{k,i} \mid \lambda_k) &= \frac{\beta_k}{\lambda_k} (t_{k,i})^{\beta_k-1} e^{-\frac{(t_{k,i})^{\beta_k}}{\lambda_k}}\,, \\
\label{eq:weibullcdf}
F(t_{k,i} \mid \lambda_k) &= 1 - e^{-\frac{(t_{k,i})^{\beta_k}}{\lambda_k}} = P(T_{k,i} \leq t_{k,i} \mid \lambda_k)\,,
\end{align}
where $\lambda_k > 0$ and $t > 0$.

The shape parameter $\beta_k$ determines whether the hazard rate is increasing ($\beta_k > 1$)
or decreasing ($\beta_k < 1$) over time.
For $\beta_k=1$, one obtains the Exponential distribution with constant hazard rate as a special case.
To keep things simple, we assume $\beta_k$ to be known.
(We plan to extend the model to learn also $\beta_k$ in a later step,
using, e.g., the discretized approach by \cite{1969:soland}.)
The scale parameter $\lambda_k$ can be interpreted through the relation
\begin{align}
\E[T_{k,i} \mid \lambda_k] &= \lambda_k^{1/\beta_k}\, \Gamma(1 + 1/\beta_k)\,.
\label{eq:lambdainterpret}
\end{align}
We will use this equation to convert expected lifetimes to $\lambda_k$ and vice versa.

With a Bayesian approach, one can express expert knowledge about the reliability of the components
by assigning a so-called prior distribution,
a distribution over the unknown parameter $\lambda_k$.
This prior distribution $f(\lambda_k)$ is then updated 
to the so-called posterior distribution $f(\lambda_k \mid \vec{t})$,
the distribution over $\lambda_k$ given the data $\vec{t}$,
via Bayes' rule
\begin{align*}
f(\lambda_k \mid \vec{t}) &\propto f(\vec{t}\mid\lambda_k) f(\lambda_k)\,.
\end{align*}
The posterior $f(\lambda_k \mid \vec{t})$ subsumes the information
from both expert knowledge and data,
and forms the basis for all inferences, like, e.g., predictions.

For the prior over $\lambda_k$,
a convenient choice is to use the inverse Gamma distribution,
which is commonly parametrized in terms of the parameters $a_k > 0$ and $b_k > 0$,
\begin{align}
f(\lambda_k\mid a_k,b_k) &= \frac{(b_k)^{a_k}}{\Gamma(a_k)} \lambda_k^{-a_k -1} e^{-\frac{b_k}{\lambda_k}}\,,
\label{eq:ig-def}
\end{align}
in short, $\lambda_k \mid a_k, b_k \sim \ig(a_k,b_k)$.
Here, we have added the prior parameters $a_k$ and $b_k$ in notation
to indicate that the prior over $\lambda$ depends on their values.

The inverse Gamma is convenient because it is a conjugate prior,
i.e., the posterior obtained by Bayes' rule is again inverse Gamma and thus easily tractable;
the prior parameters only need to be updated to obtain the posterior parameters,
so no numerical integation or simulation techniques are necessary.
Furthermore, this conjugacy holds also when right-censored observations are used for updating,
as indicated below.

In place of the usual parametrization in terms of $a_k$ and $b_k$,
we use the parameters $\nkz > 1$ and $\ykz > 0$
because they have a simple interpretation.
They are defined as
\begin{align}
\nkz &= a_k - 1 & &\text{ and}
&
\ykz &= b_k / \nkz,
\label{eq:abtony}
\end{align}
where $\ykz$ can be interpreted as the prior guess for the scale parameter $\lambda_k$,
as $\E[\lambda_k\mid\nkz,\ykz] = \ykz$.
Using \eqref{eq:lambdainterpret},
we can thus translate an expert's statement of expected component lifetime into a corresponding value for $\ykz$.
$\nkz$ can be seen as a prior strength or pseudocount,
this will become clear in the discussion of the update step below.

The parametrization in terms of $\nkz$ and $\ykz$ also clarifies the nature of the combination
of prior information and data through Bayes' rule.
In the conjugate setting,
applying Bayes' rule simply means that the prior parameters $\nkz$ and $\ykz$
are updated to posterior parameters, which we denote by $\nkn$ and $\ykn$, respectively.
Assume we observe $n_k = e_k + c_k$ component lifetimes,
where $e_k$ is the number of actual failure events,
and $c_k$ is the number of right-censored observations.
We denote the failure times by $t_{k,1}, \ldots, t_{k,e_k}$,
and the censoring times by $t^+_{k,1}, \ldots, t^+_{k,c_k}$,
and collect them in an observation vector $\vec{t}_k = (t_{k,1}, \ldots, t_{k,e_k}, t^+_{k,1}, \ldots, t^+_{k,c_k})$.
Then, the updated, posterior parameters are
\begin{align}
\nkn &= \nkz + e_k\,, 
&
\ykn &=  \frac{\nkz \ykz + \tautk}{\nkz + e_k}\,,
\label{eq:ig-update}
\end{align}
where $\tautk = \sum_{i=1}^{e_k} (t_{k,i})^\beta + \sum_{i=1}^{c_k} (t^+_{k,i})^\beta$.

From the simple update rule \eqref{eq:ig-update}, we see that
$\ykn$ is a weighted average of the prior parameter $\ykz$ and the maximum likelihood (ML) estimator $\tautk/e_k$,
with weights proportional to $\nkz$ and $e_k$, respectively.
$\nkz$ can thus be interpreted as a prior strength or pseudocount,
indicating how much our prior guess should weigh against the $e_k$ observed failure events.
Furthermore, $\V[\lambda\mid\nkz,\ykz] = (\ykz)^2 / (1 - 1/\nkz)$;
for fixed $\ykz$, a higher $\nkz$ indicates thus 
that more probability mass is concentrated around $\ykz$.

Using \eqref{eq:abtony} and \eqref{eq:ig-update}, the posterior distribution over $\lambda_k$ is
\begin{align}
\lambda_k \mid \nkz, \ykz, \vec{t}_k \sim \ig(\nkz + e_k + 1, \nkz \ykz + \tautk)\,.
\label{eq:ig-update-alpha}
\end{align}
%where we have added the prior parameters $\nkz$ and $\ykz$ in notation
%to emphasize that the posterior is a synthesis of prior information and data.
As this posterior \eqref{eq:ig-update-alpha} can be defined in terms of
the updated, posterior parameters $\nkn$ and $\ykn$,
we may also write
\begin{align*}
f(\lambda_k \mid \nkz, \ykz, \vec{t}_k) &= f(\lambda_k \mid \nkn, \ykn)\,.
\end{align*}
The iterative nature of Bayesian inference means that we can take the updated,
posterior parameters as new prior parameters and update them again using new data.
Indeed, we will use this property to use the extra information about components
that accumulates during operation of the system:
At any time $\tnow > 0$,
all non-failed components correspond to a right censored observation $\tpnow$;
any failed components instead contribute a fully observed, non-censored lifetime,
and both types of observations can be used in the update step \eqref{eq:ig-update}.
To keep notation simple,
we will below denote the parameters of the inverse Gamma distribution by $\nkz$ and $\ykz$,
regardless of them expressing expert information alone,
or stemming from the combination of expert information and test data.


\section{Reliability functions for complex systems using the survival signature}
\label{sec:sysrel}

The goal is to find, for a given monitored system, the system reliability curve $\Rsys(t)$ at current time $\tnow$,
and we will now show how the system reliability function can be efficiently obtained using the survival signature.
This system reliability gives us the RUL distribution on which we base our adaptive maintenance policy.

We consider systems of arbitrary reliability block diagram layout,
consisting of components of $K$ different types,
and there are $n_k$ components of type $k$ in the system.
This system is observed until time $\tnow$,
leading to censored observation of lifetimes of components within the system.



\section{Posterior predictive***}

For this, we need the posterior predictive distribution
of the number of components that function at times $t > \tnow$,
which we will derive .


\section{***from reliability curve (RUL) to maintenance decision}

To find the optimal moment for maintenance based on the current set of system reliability curves,
we minimize the expected average cost per time unit,
called the unit cost rate, $g(\tau)$,
to find the cost-optimal moment of maintenance $\tau^*$
(could be discounted as well, out of scope here.)

In the literature, commonly two ways to calculate the unit cost rate are considered,
a renewal theory based long-term unit cost rate,
and the one-cycle cost rate 
\citep{1984:ansell-bendell-humble,1996:mazzuchi-soyer,2006:coolen-schrijner-coolen}.
Although the renewal theory based unit cost rate is often used
in CBM literature \citep{2013:si-et-al,2011:kim-et-al},
%As we discussed in the Introduction,
we use the one-cycle cost rate as it is the most appropriate for our situation.
%since it considers only the costs with respect to the current cycle.

Let $c_p$ be the cost of planned / preventive maintenance, and $c_u$ the cost of unplanned / breakdown maintenance, where $c_p < c_u$.
As discussed in the Introduction,
we assume that both $c_p$ and $c_u$ include the cost of replacing all components in the system.
Usually, set-up costs, work costs and downtime costs are much higher for unplanned / breakdown maintenance,
such that often, $c_p \ll c_u$.

Conditional on the (random) system failure time $\Tsys$, the unit cost rate is 
\begin{align*}
g(\tau \mid \Tsys) &=
\begin{cases}
c_p / \tau  & \text{if } \Tsys \ge \tau \\
c_u / \Tsys & \text{if } \Tsys < \tau
\end{cases}
\end{align*}

Taking the expectation over $\Tsys$ leads to the expected unit cost rate being
\begin{align}
g(\tau) &= \E[g(\tau \mid \Tsys)] = \frac{c_p}{\tau} \Rsys(\tau) + c_u \int_0^\tau \frac{1}{t} \fsys(t) \dd t
\label{eq:gtau}
\end{align}
***here, $\Rsys(\cdot)$ shifted such that $\tnow = 0$.

We approximate the integral in \eqref{eq:gtau} numerically by a sum,
where $\fsys(t)$ is calculated via differencen of $\Rsys(t)$ values on a dense grid.
$g(\tau)$ is likewise evaluated on a dense grid,
and $\tau^*_{\tnow} = \arg\min g(\tau)$ is determined as the minimum over the grid.
The lower index $\tnow$ of the optimal moment of maintenance serves to remind that
$\tau^*$ depends on $\tnow$, and also on the history of the system.

At time $\tnow$, the corresponding $\tau^*_{\tnow}$ gives the optimal moment of maintenance in terms of time to elapse after $\tnow$,
so in the absolute time scale, the optimal moment of maintenance is at $\tnow + \tau^*_{\tnow}$.

****plot both $\tau^*_{\tnow}$ and $\tnow + \tau^*_{\tnow}$ over time for different failure histories


\section{Comparison with $M^*$ out of $N$ policy}

***


\section{Case study / numerical example for complex system layout}

which system layout? something that demonstrates the power of the method (complex layout) or something simple?

complex: e.g., bridge system where each of the four elements is a two out of three, and the bridge element is a two-parallel.

or the simplified brake system from ASCE-ASME paper?


\section{Outlook}

*** study other replacement schemes, e.g., replacing only failed components:
when repaired/replaced components are present in system,
then one needs to use actual ages (and not time since system startup) in parameter update,
introduces new component type for $\Rsys(t)$ calculation but with same posterior parameters as unreplaced component type.
Repaired/replaced components require the creation of a separate type in the survival signature decomposition
and thus the calculation of separate posterior predictive probabilities
$P(C^k_t = l_k \mid \nkz,\ykz,\text{test data},\text{monitoring data})$,
which use, however, the same hyperparameter learning (using actual component ages) as the `parent type'.


*** move to sets of priors, set of RUL distributions like in \cite{2016:walter-coolen}.
Leads to set of $g(\tau)$, finding (set of) $\tau^*$ is then non-trivial,
needs decision criteria from IP literature like E-admissibility, maximality, or maximin.

*** to use the model for inspection-based CBM (if no repair necessary, find optimal timing of next inspection),
we would need to add interval-censored data (failure has happened between last and current inspection)



\section*{Acknowledgements}

CAMPI

Frank Coolen for inspiring discussions

\section*{Bibliography}

\bibliographystyle{elsarticle-harv}

\bibliography{refs}

\end{document}
